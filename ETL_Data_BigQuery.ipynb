{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Calling API to get job details"
      ],
      "metadata": {
        "id": "P9j328Yk5MHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Define roles and constants\n",
        "roles = [\"ML EngineerÂ \",\n",
        "\"Cybersecurity engineer\",\n",
        "\"QA Engineer\",\n",
        "\"Data Scientist\",\n",
        "\"Data Analyst\",\n",
        "\"Software Developer\",\n",
        "\"Web Developer\"]\n",
        "\n",
        "api_key = \"123\"  # Replace with your actual API key\n",
        "base_url = f\"https://serpapi.com/search?engine=google_jobs&hl=en&api_key={api_key}\"\n",
        "calls_per_role = 25\n",
        "\n",
        "def fetch_jobs_for_role(role):\n",
        "    \"\"\"\n",
        "    Fetch jobs for a given role, making up to `calls_per_role` API calls using pagination.\n",
        "    \"\"\"\n",
        "    all_jobs = []\n",
        "    current_url = f\"{base_url}&q={role.replace(' ', '+')}\"\n",
        "\n",
        "    for call in range(calls_per_role):\n",
        "        print(f\"Fetching page {call + 1} for role: {role}\")\n",
        "        current_url = current_url + f\"&api_key={api_key}\"\n",
        "        response = requests.get(current_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Error: {response.status_code} for {current_url}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract job results\n",
        "        if \"jobs_results\" in data:\n",
        "            for job in data[\"jobs_results\"]:\n",
        "                # Add role to the job data\n",
        "                job[\"role\"] = role\n",
        "                all_jobs.append(job)\n",
        "        else:\n",
        "            print(\"No jobs found in response.\")\n",
        "            break\n",
        "\n",
        "        # Get the next page URL\n",
        "        pagination = data.get(\"serpapi_pagination\", {})\n",
        "        next_url = pagination.get(\"next\")\n",
        "        if not next_url:\n",
        "            print(\"No more pages available.\")\n",
        "            break\n",
        "\n",
        "        current_url = next_url  # Update the URL for the next call\n",
        "\n",
        "    return all_jobs\n",
        "\n",
        "def main():\n",
        "    all_roles_jobs = []\n",
        "\n",
        "    for role in roles:\n",
        "        role_jobs = fetch_jobs_for_role(role)\n",
        "        all_roles_jobs.extend(role_jobs)\n",
        "\n",
        "    # Convert to a pandas DataFrame\n",
        "    jobs_df = pd.DataFrame(all_roles_jobs)\n",
        "    print(f\"Final DataFrame contains {len(jobs_df)} job postings.\")\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    jobs_df.to_csv(\"/content/drive/MyDrive/Data_Management/all_jobs.csv\", index=False)\n",
        "    print(\"Saved all jobs\")\n",
        "\n",
        "    return jobs_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    final_df = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbKrC1XvoVe8",
        "outputId": "8885d21e-ea68-4271-842d-654f6b2be201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 1 for role: Web Developer\n",
            "Fetching page 2 for role: Web Developer\n",
            "Fetching page 3 for role: Web Developer\n",
            "Fetching page 4 for role: Web Developer\n",
            "Fetching page 5 for role: Web Developer\n",
            "Fetching page 6 for role: Web Developer\n",
            "Fetching page 7 for role: Web Developer\n",
            "Fetching page 8 for role: Web Developer\n",
            "Fetching page 9 for role: Web Developer\n",
            "Fetching page 10 for role: Web Developer\n",
            "Fetching page 11 for role: Web Developer\n",
            "Fetching page 12 for role: Web Developer\n",
            "Fetching page 13 for role: Web Developer\n",
            "Fetching page 14 for role: Web Developer\n",
            "No jobs found in response.\n",
            "Final DataFrame contains 128 job postings.\n",
            "Saved all jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making one final CSV file"
      ],
      "metadata": {
        "id": "bc3QAXcx5PpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "path = '/content/drive/MyDrive/Data_Management'\n",
        "file_paths = glob.glob(path + \"/*.csv\")"
      ],
      "metadata": {
        "id": "WJdjvw6UwH-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_csv_files(file_paths):\n",
        "    # Initialize an empty list to store DataFrames\n",
        "    dataframes = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        # Read each file and append it to the list\n",
        "        df = pd.read_csv(file_path)\n",
        "        dataframes.append(df)\n",
        "\n",
        "    # Concatenate all DataFrames, aligning columns by name\n",
        "    final_df = pd.concat(dataframes, ignore_index=True, sort=False)\n",
        "    return final_df\n",
        "\n",
        "# Concatenate all CSVs into one DataFrame\n",
        "final_dataframe = concatenate_csv_files(file_paths)\n",
        "\n",
        "# Save the final DataFrame to a new CSV file\n",
        "final_dataframe.to_csv('/content/drive/MyDrive/Data_Management/final_all_jobs.csv', index=False)\n",
        "\n",
        "# Display basic information about the final DataFrame\n",
        "print(f\"Final DataFrame shape: {final_dataframe.shape}\")\n",
        "print(\"Saved as: /content/drive/MyDrive/Data_Management/final_all_jobs.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiw2gJcb4xlu",
        "outputId": "2ee7853b-ea9f-4d63-8c09-43d2ddfbed8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final DataFrame shape: (1959, 21)\n",
            "Saved as: /content/drive/MyDrive/Data_Management/final_all_jobs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df =df[['title', 'company_name', 'location', 'via', 'share_link', 'thumbnail',\n",
        "       'extensions', 'detected_extensions', 'job_highlights',\n",
        "       'apply_options', 'job_id', 'role']]\n",
        "df.to_csv('/content/drive/MyDrive/Data_Management/final_all_jobs.csv', index=False)\n"
      ],
      "metadata": {
        "id": "OSYexH-i5JOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pushing to big query table"
      ],
      "metadata": {
        "id": "_JDJCWqm5dN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQPrBAB96wgA",
        "outputId": "297c93db-a5f1-4c8c-b109-6df497d81bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.25.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is71l1wz_wvb",
        "outputId": "c15f606c-a9e9-4f21-a63c-355c0b458b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=Fony3duEuHDj1D9No0ekAI2oFwROEb&prompt=consent&token_usage=remote&access_type=offline&code_challenge=63Thw0GcwDjI-iYCJpY1WbgnhVd4zbl_Lz5lgbmxnDM&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AeanS0Z4QP93iaR2JJ5UkjV2HXixvx5kuZ0_rwQnPR7RhJsShuvEUk_yTlvdyiYMQ4_Ppg\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Define variables\n",
        "project_id = \"gcp-services-442706\"\n",
        "dataset_id = \"data_management\"\n",
        "table_id = \"jobs\"\n",
        "\n",
        "# Load CSV into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data_Management/final_all_jobs.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tb4VkKs_yUN",
        "outputId": "e658c12c-6c13-4a6f-b5ba-51f569a459e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzZXWTGgBALA",
        "outputId": "8dc83586-9c40-4371-cf08-ff0e6ebda7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['title', 'company_name', 'location', 'via', 'share_link', 'thumbnail',\n",
              "       'extensions', 'detected_extensions', 'job_highlights', 'apply_options',\n",
              "       'job_id', 'role'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Define BigQuery table reference\n",
        "table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "# Define job configuration\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  # Overwrite table; change to WRITE_APPEND if needed\n",
        "    source_format=bigquery.SourceFormat.CSV,  # Specify CSV as source\n",
        "    autodetect=True,  # Auto-detect schema based on CSV\n",
        ")\n",
        "\n",
        "# Load data to BigQuery\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()\n",
        "\n",
        "# Verify upload\n",
        "table = client.get_table(table_ref)  # Get the table information\n",
        "print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_ref}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhY62c3PABgI",
        "outputId": "6bfa9f7d-cf7c-4442-cbbc-728edf0d16bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 653 rows and 12 columns to gcp-services-442706.data_management.jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Transformation and expansion of columns\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoZcWdMp6pzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Assuming the data is already loaded into a DataFrame called `df`\n",
        "\n",
        "# Sample representation of loading the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data_Management/final_all_jobs.csv')\n"
      ],
      "metadata": {
        "id": "3tCnNQ_a5gud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_dict_column(df, column_name):\n",
        "    # Convert stringified dictionaries into Python dictionaries\n",
        "    df[column_name] = df[column_name].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "    # Normalize the dictionary column into separate columns\n",
        "    expanded_df = pd.json_normalize(df[column_name])\n",
        "\n",
        "    # Combine the original DataFrame with the expanded DataFrame\n",
        "    df = pd.concat([df.drop(columns=[column_name]), expanded_df], axis=1)\n",
        "    return df\n",
        "\n",
        "# Expand the 'detected_extensions' column\n",
        "df = expand_dict_column(df, \"detected_extensions\")\n",
        "\n",
        "# Display the final DataFrame\n",
        "# print(df)\n",
        "\n",
        "# Save to a CSV file (optional)\n",
        "df.to_csv('/content/drive/MyDrive/Data_Management/final_all_jobs_transformed.csv', index=False)"
      ],
      "metadata": {
        "id": "mjyZhTZU8zxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "vz6qKfpQ9lKo",
        "outputId": "2c68e757-56db-414d-a2dd-9e0969412934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            title               company_name       location  \\\n",
              "0                  Data Scientist              Wipro Limited      Tampa, FL   \n",
              "1  Health Services Data Scientist  Manatee County Government  Bradenton, FL   \n",
              "\n",
              "             via                                         share_link  \\\n",
              "0  Wipro Careers  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
              "1         Indeed  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
              "\n",
              "                                           thumbnail  \\\n",
              "0  https://serpapi.com/searches/6743c6b95ed3cab06...   \n",
              "1  https://serpapi.com/searches/6743c6b95ed3cab06...   \n",
              "\n",
              "                                          extensions  \\\n",
              "0                  ['Full-time', 'Health insurance']   \n",
              "1  ['4 days ago', '54,709.20â82,009.20 a year', '...   \n",
              "\n",
              "                                      job_highlights  \\\n",
              "0  [{'title': 'Qualifications', 'items': ['Work A...   \n",
              "1  [{'title': 'Qualifications', 'items': ['Liftin...   \n",
              "\n",
              "                                       apply_options  \\\n",
              "0  [{'title': 'Wipro Careers', 'link': 'https://c...   \n",
              "1  [{'title': 'Indeed', 'link': 'https://www.inde...   \n",
              "\n",
              "                                              job_id            role  \\\n",
              "0  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImNvbX...  Data Scientist   \n",
              "1  eyJqb2JfdGl0bGUiOiJIZWFsdGggU2VydmljZXMgRGF0YS...  Data Scientist   \n",
              "\n",
              "  schedule_type health_insurance   posted_at                      salary  \\\n",
              "0     Full-time             True         NaN                         NaN   \n",
              "1     Full-time              NaN  4 days ago  54,709.20â82,009.20 a year   \n",
              "\n",
              "  paid_time_off dental_coverage work_from_home qualifications  \n",
              "0           NaN             NaN            NaN            NaN  \n",
              "1           NaN             NaN            NaN            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80627b36-6a72-4d09-88f7-308c7f8bb7b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>company_name</th>\n",
              "      <th>location</th>\n",
              "      <th>via</th>\n",
              "      <th>share_link</th>\n",
              "      <th>thumbnail</th>\n",
              "      <th>extensions</th>\n",
              "      <th>job_highlights</th>\n",
              "      <th>apply_options</th>\n",
              "      <th>job_id</th>\n",
              "      <th>role</th>\n",
              "      <th>schedule_type</th>\n",
              "      <th>health_insurance</th>\n",
              "      <th>posted_at</th>\n",
              "      <th>salary</th>\n",
              "      <th>paid_time_off</th>\n",
              "      <th>dental_coverage</th>\n",
              "      <th>work_from_home</th>\n",
              "      <th>qualifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Wipro Limited</td>\n",
              "      <td>Tampa, FL</td>\n",
              "      <td>Wipro Careers</td>\n",
              "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
              "      <td>https://serpapi.com/searches/6743c6b95ed3cab06...</td>\n",
              "      <td>['Full-time', 'Health insurance']</td>\n",
              "      <td>[{'title': 'Qualifications', 'items': ['Work A...</td>\n",
              "      <td>[{'title': 'Wipro Careers', 'link': 'https://c...</td>\n",
              "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImNvbX...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Health Services Data Scientist</td>\n",
              "      <td>Manatee County Government</td>\n",
              "      <td>Bradenton, FL</td>\n",
              "      <td>Indeed</td>\n",
              "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
              "      <td>https://serpapi.com/searches/6743c6b95ed3cab06...</td>\n",
              "      <td>['4 days ago', '54,709.20â82,009.20 a year', '...</td>\n",
              "      <td>[{'title': 'Qualifications', 'items': ['Liftin...</td>\n",
              "      <td>[{'title': 'Indeed', 'link': 'https://www.inde...</td>\n",
              "      <td>eyJqb2JfdGl0bGUiOiJIZWFsdGggU2VydmljZXMgRGF0YS...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4 days ago</td>\n",
              "      <td>54,709.20â82,009.20 a year</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80627b36-6a72-4d09-88f7-308c7f8bb7b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80627b36-6a72-4d09-88f7-308c7f8bb7b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80627b36-6a72-4d09-88f7-308c7f8bb7b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cd2ce03-a05d-4c9e-9381-a3316c3fde23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cd2ce03-a05d-4c9e-9381-a3316c3fde23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cd2ce03-a05d-4c9e-9381-a3316c3fde23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 653,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 502,\n        \"samples\": [\n          \"Principal Cyber Engineer - P4\",\n          \"Engineer Software I\",\n          \"Cybersecurity Engineer More Details\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 503,\n        \"samples\": [\n          \"DKMRBH Inc\",\n          \"Veeva Systems\",\n          \"WARNERMEDIA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 326,\n        \"samples\": [\n          \"Piscataway, NJ\",\n          \"North Charleston, SC\",\n          \"Secaucus, NJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"via\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 229,\n        \"samples\": [\n          \"Idealist\",\n          \"Space Crew\",\n          \"Jobs - Towards AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"share_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 650,\n        \"samples\": [\n          \"https://www.google.com/search?ibp=htl;jobs&q=Web+Developer&htidocid=EkBolKuhvLRKJ4GNAAAAAA%3D%3D&hl=en-US&shndl=-1&source=sh/x/job/li/m1/1#fpstate=tldetail&htivrt=jobs&htiq=Web+Developer&htidocid=EkBolKuhvLRKJ4GNAAAAAA%3D%3D\",\n          \"https://www.google.com/search?ibp=htl;jobs&q=Data+Analyst&htidocid=IB3VJpRysum0akJUAAAAAA%3D%3D&hl=en-US&shndl=-1&source=sh/x/job/li/m1/1#fpstate=tldetail&htivrt=jobs&htiq=Data+Analyst&htidocid=IB3VJpRysum0akJUAAAAAA%3D%3D\",\n          \"https://www.google.com/search?ibp=htl;jobs&q=QA+Engineer&htidocid=MXSVFZFgb7Nf3kBEAAAAAA%3D%3D&hl=en-US&shndl=37&shmd=H4sIAAAAAAAA_yWNsQrCMBBAce0nON0kKtiI4KJTEZEIDiLO5RqPNNLehVyE-jn-qRaXNz3eKz6TYnat4Mg-MFECay2s4CwNKGFyLQjDScR3NN23OUfdGaPalV4z5uBKJ70RpkYG85RGR9TaYqLYYaZ6s10PZWS_3FVj7CIpe_QElvWVkB3BQfqI_Ib5X7ALCAx3DpkecPs9SL-7a3g7pAAAAA&shmds=v1_AXX-3kE2KqIf_ZgxZTx7reBMMHjEpVs1T87HqQzcq8UzpaEs2w&shem=jblt,jbolt&source=sh/x/job/li/m1/1#fpstate=tldetail&htivrt=jobs&htiq=QA+Engineer&htidocid=MXSVFZFgb7Nf3kBEAAAAAA%3D%3D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thumbnail\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 404,\n        \"samples\": [\n          \"https://serpapi.com/searches/6743c96c72e5c4a99b483fc6/images/48edc94a9f737b1728fa1accd174cdea695bb487b25f33abb52d21ef3bde5194.gif\",\n          \"https://serpapi.com/searches/6743c9db059caf7346c74468/images/7c1931d0fefdb5c57b3361891285761f23e9c437366d5f3a0ca73441865f5ed5.gif\",\n          \"https://serpapi.com/searches/6743ce946531cb2562b3b63b/images/52710f701064f575522714d9d7d53f8bf052fffe743c39bf1fc56f5b0e19de68.gif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extensions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 355,\n        \"samples\": [\n          \"['7 days ago', 'Full-time', 'No degree mentioned']\",\n          \"['11 days ago', 'Full-time', 'Paid time off', 'Dental insurance', 'Health insurance']\",\n          \"['1 day ago', 'Full-time', 'No degree mentioned']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_highlights\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 560,\n        \"samples\": [\n          \"[{'title': 'Qualifications', 'items': ['As the AI Lead Engineer, you should have a strong technical background and demonstrated experience in Data Science , MLOps and AI/ML Engineering', 'Proficiency in Google Cloud Platform (GCP) services relevant to machine learning and AI, such as AI Platform, BigQuery, Dataflow, and Tensorflow', 'Strong understanding of machine learning algorithms, techniques, and frameworks, including deep learning, neural networks, and ensemble methods', 'Experience with building and training machine learning models using tools like TensorFlow, Keras, or PyTorch', 'Familiarity with cloud-based data storage and processing technologies for handling large datasets efficiently', 'Proficiency in programming languages such as Python for data manipulation, analysis, and model development', 'Experience with version control systems like Git for managing code repositories and collaboration', 'Understanding of containerization technologies like Docker for packaging machine learning models and deploying them in production', 'Strong problem-solving skills, analytical thinking, and the ability to communicate complex technical concepts effectively', 'Experience with Gen AI,', 'Strong in Software Engineering practices and be able to translate those practices into the AI Engineering world', 'Bachelor\\u2019s Degree in related field (e.g', 'Data Science, Predictive Analytics, Statistics, Marketing Analytics, Applied Mathematics, IT or a combination of education and experience', '4+ years of experience acting as the senior technical lead helping facilitate analytical/technical discussions on solution tradeoffs for new feature implementations', '3+ years of experience of analytical methods and their proper application', '3+ years of experience using AI/ML, data science software (e.g., Python-based tools)', '2+ years leading and managing direct reports', 'Experience in leading, hiring and growing Data Science teams', 'Experience using Cloud Platforms and AI Platforms', 'Experience using Gen AI technologies', 'PhD Degree in related field (e.g., Data Science, Predictive Analytics, Machine Learning, Statistics, Applied Mathematics, Computer Science)', 'Expert level of Advanced and Predictive Analytical Methods e.g., Simulation, Design of Experiments, Genetic Algorithms, Ensemble Methods, Na\\u00efve Bayes, Neural Networks, regression, image processing, natural language processing,', 'Working knowledge of GCP', 'Expertise in open source data science technologies such as Python, R, Spark, SQL', 'Candidates for positions with Ford Motor Company must be legally authorized to work in the United States']}, {'title': 'Benefits', 'items': ['Immediate medical, dental, vision and prescription drug coverage', 'Flexible family care days, paid parental leave, new parent ramp-up programs, subsidized back-up child care and more', 'Family building benefits including adoption and surrogacy expense reimbursement, fertility treatments, and more', 'Vehicle discount program for employees and family members and management leases', 'Tuition assistance', 'Established and active employee resource groups', 'Paid time off for individual and team community service', 'A generous schedule of paid holidays, including the week between Christmas and New Year\\u2019s Day', 'Paid time off and the option to purchase additional vacation time', 'https://fordcareers.co/LL6HTHD (https://urldefense.com/v3/__https:/fordcareers.co/LL6HTHD__;!!N_LtwI-RPugbI9wg0dJn!Hmm9lb5C6sSrhxLGSuLpcqEyss3xENIGbgIGyFfg_Kfsvxa32gVwgVC89HMc55FEXi-Nd0TvtAs1xUU$)']}, {'title': 'Responsibilities', 'items': ['You will be responsible for the delivery of analytical models and solutions as well as use your business acumen, knowledge of data, and AI to support key products within Pro Tech that focus on improving customer experience, increasing revenue, and improving efficiency across the business', 'You will be responsible for coaching and providing growth opportunities to direct reports', 'The candidate will be able to develop healthy relationships and trust with business stakeholders and peers across Ford Pro-Tech', 'Strategic Thinking & Leadership', 'Collaborate with business customers to understand business challenges and develop strategies for solving them using AI/ML and advanced analytics', 'Help define and communicate product vision and delivery with key stakeholders', 'Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends', 'Support technical reviews of analytical methods & AI solutions', 'Support the prioritization of advanced analytic research needed to advance the product\\u2019s capabilities', 'Hands on leadership of developing analytical solutions', 'Establish and grow our AI Engineering practice', 'Drive AI products and services end-to-end in partnership with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions', 'Influence product direction through clear and compelling presentations to leadership', 'Contribute towards advancing the AI Engineering and Data Science discipline in Ford Pro through the Community of Practice, including but not limited to driving data best practices, improving analytical processes, scaling knowledge and tools, and mentoring other data scientists', 'Promote and facilitate learning and development needs of team', 'Support team members as part of product delivery model', 'Ability to design and implement end-to-end machine learning pipelines for data ingestion, processing, modeling, and deployment']}]\",\n          \"[{'title': 'Qualifications', 'items': ['Support the production readiness evaluation process, including Post Deployment Testing, risk assessment, and sign-off.Participate in end-of-release reviews, suggest improvements, and implement lessons learned.QualificationsBachelor\\u2019s degree in computer science or a related discipline, or 1 to 2 years\\u2019 experience in a QA or development role', 'Good understanding of QA processes and the Software Development/Testing Lifecycle (SDLC/STLC).Experience with some of the following: Windows O/S, Browser compatibility, GIT, Azure, Oracle or rational DBs, SQL, UNIX/LINUX user commands/editors/shell scripts, web services, batch file scripting & testing C# based applications, selenium, VMware, Postman, and developing API and Service level tests', 'Excellent oral and written communication skills, with the ability to present and discuss technical information in a way that establishes rapport, persuades others, and gains understanding', 'Fluency in English is essential', 'Knowledge of API/UI automation testing tools; Ready API, Selenium, Cypress, Playwright, or any other related tool', 'Familiarity with open-source technologies', 'Proficiency in the use of some of the supported QA tool suite', 'Ability to utilize process, problem-solving, and prioritization techniques such as process mapping, mind maps, time management, cause & effect, and root cause analysis with support']}, {'title': 'Responsibilities', 'items': ['This role requires a broad knowledge of the principles, practices, and procedures of software testing', 'You will apply that knowledge through the design, creation, automation, and execution of test plans', 'You will log defects and provide status reports of application testing on projects', 'Key ResponsibilitiesParticipate in the QA team\\u2019s test planning, test execution and project closeout', 'Follow QA best practices/methodologies with end-to-end testing using manual or automated tools', 'Execute test plans, test cases, and test scripts with minimal assistance, taking ownership of reporting issues', 'Continually automate manual tests and integrate them into automated regression test suites', 'Collaborate with the automation team to create automated tests early in the Software Development/Testing Lifecycle (SDLC/STLC).Assist in documenting processes related to Kaseya\\u2019s QA department']}]\",\n          \"[{'title': 'Qualifications', 'items': ['Experience with the Ansible Automation Platform and/or experience with other configuration management and infrastructure as code tooling such as Hashicorp Terraform', 'Significant experience with Python, Django and Django REST Framework', 'Ability to work Hybrid from Raleigh NC, Durham NC, Boston MA or Lowell MA', 'Experience with Python unit and integration testing with tools such as pytest', 'Experience with Linux', 'Experience with SQL and relational databases such as PostgreSQL', 'Experience with utilizing container management platforms and development environments like Kubernetes, OpenShift, and Docker/Docker Compose', 'Experience with CI/CD systems like Jenkins and GitHub Actions', 'Team leadership experience', 'Demonstrated ability to quickly and accurately troubleshoot system and performance issues', 'Good communications skills, and experience working directly with and presenting to stakeholders', 'An aptitude for jumping in to help unblock, mentor and learn from others']}, {'title': 'Benefits', 'items': ['The salary range for this position is $142,140.00 - $234,500.00', 'Actual offer will be based on your qualifications', 'Pay Transparency', 'Red Hat determines compensation based on several factors including but not limited to job location, experience, applicable skills and training, external market value, and internal pay equity', 'Annual salary is one component of Red Hat\\u2019s compensation package', 'This position may also be eligible for bonus, commission, and/or equity', 'Comprehensive medical, dental, and vision coverage', 'Flexible Spending Account - healthcare and dependent care', 'Health Savings Account - high deductible medical plan', 'Retirement 401(k) with employer match', 'Paid time off and holidays', 'Paid parental leave plans for all new parents', 'Leave benefits including disability, paid family medical leave, and paid military leave', 'Additional benefits including employee stock purchase plan, family planning reimbursement, tuition reimbursement, transportation expense account, employee assistance program, and more!', 'Note: These benefits are only applicable to full time, permanent associates at Red Hat located in the United States']}, {'title': 'Responsibilities', 'items': ['In this role, you will work closely with a group of talented engineers helping to improve efficiency and drive results through your contributions', 'You will work closely with engineers across the Ansible organization to deliver features that can be used across our projects', 'Design, develop and test new backend features for Ansible Automation Platform', 'Troubleshoot bugs and regressions, working closely with Quality Engineers to deliver working and feature-complete solutions', 'Participate in product release cycles, deploying code to integration, staging and production environments, integrating with CI/CD tooling', 'Perform software updates, peer code reviews, testing, and CVE analysis', 'Help mentor and learn from other engineers in a highly-collaborative team environment, as well as participate in peer code reviews', 'Regularly participate in the team\\u2019s Agile scrum process, demos and check-ins with Product Management and other stakeholders to align on use-cases and plan new initiatives']}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apply_options\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 638,\n        \"samples\": [\n          \"[{'title': 'Mayo Clinic Careers', 'link': 'https://jobs.mayoclinic.org/job/jacksonville/senior-data-science-analyst/33647/63571128624?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Mayo-Clinic/Job/Senior-Data-Science-Analyst/-in-Jacksonville,FL?jid=261352a84326c6eb&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'Indeed', 'link': 'https://www.indeed.com/viewjob?jk=f5bce408c1720032&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'Dice', 'link': 'https://www.dice.com/job-detail/6d72ef45-25f5-4868-bac1-9b7df0e0dfd7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/senior-data-science-analyst-mayo-clinic-JV_IC1154093_KO0,27_KE28,39.htm?jl=1009224929275&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/senior-data-science-analyst-at-mayo-clinic-3959119895?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'Ladders', 'link': 'https://www.theladders.com/job/senior-data-science-analyst-mayoclinic-jacksonville-fl_73513816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, {'title': 'JobzMall', 'link': 'https://www.jobzmall.com/mayo-clinic/job/senior-data-science-analyst-7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}]\",\n          \"[{'title': 'Salary.com', 'link': 'https://www.salary.com/job/smartiplace/data-analyst-tableau-alteryx-developer-advanced-level-w2-only/j202406202115574862733?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}]\",\n          \"[{'title': 'Recruiter Jobs', 'link': 'https://jobs.recruiter.com/jobs/11904081678-senior-data-scientist-gt-school-remote-60-000-year-usd?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 639,\n        \"samples\": [\n          \"eyJqb2JfdGl0bGUiOiJFbmdpbmVlciBTb2Z0d2FyZSBJIiwiY29tcGFueV9uYW1lIjoiRmxpZ2h0U2FmZXR5IEludGVybmF0aW9uYWwiLCJhZGRyZXNzX2NpdHkiOiJCcm9rZW4gQXJyb3csIE9LIiwiaHRpZG9jaWQiOiJ4dU1QdHh5azRMclRZa2F5QUFBQUFBPT0iLCJobCI6ImVuIn0=\",\n          \"eyJqb2JfdGl0bGUiOiJBV1MgQ2xvdWQgQ3liZXJzZWN1cml0eSBFbmdpbmVlciAtIEh5YnJpZCBqb2JzIGluIENhc3RsZSBQaW5lcywgQ08gfCBNeVR1cm4uQ2FyZWVycyIsImNvbXBhbnlfbmFtZSI6IkNoYXJsZXMgU2Nod2FiIiwiYWRkcmVzc19jaXR5IjoiQ2FzdGxlIFBpbmVzLCBDTyIsImh0aWRvY2lkIjoieW1aU1BkWVoxbEd2cEVGNEFBQUFBQT09IiwiaGwiOiJlbiJ9\",\n          \"eyJqb2JfdGl0bGUiOiJDb2xsZWdlIEFpZGUgLSBXZWIgRGV2ZWxvcGVyIiwiY29tcGFueV9uYW1lIjoiT0ZGSUNFIE9GIFRIRSBDT01QVFJPTExFUiIsImFkZHJlc3NfY2l0eSI6IkNsYXksIE5ZIiwiaHRpZG9jaWQiOiJwTS12V05BelJ6Qmg0OXZsQUFBQUFBPT0iLCJobCI6ImVuIn0=\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Data Scientist\",\n          \"Software Developer\",\n          \"ML Engineer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"schedule_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Full-time and Contractor\",\n          \"Contractor\",\n          \"Part-time\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"health_insurance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posted_at\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"1 month ago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 119,\n        \"samples\": [\n          \"119,257\\u2013162,623 a year\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paid_time_off\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dental_coverage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"work_from_home\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qualifications\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"No degree mentioned\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjAK31i5_mKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Data pushing to big query table"
      ],
      "metadata": {
        "id": "eygEr74KB6fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Define variables\n",
        "project_id = \"gcp-services-442706\"\n",
        "dataset_id = \"data_management\"\n",
        "table_id = \"jobs-transformed\"\n",
        "\n",
        "# Load CSV into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data_Management/final_all_jobs_transformed.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1_TtsqtB6wX",
        "outputId": "e8b4372f-4878-4a66-a639-231cdb36465d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Define BigQuery table reference\n",
        "table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "# Define job configuration\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  # Overwrite table; change to WRITE_APPEND if needed\n",
        "    source_format=bigquery.SourceFormat.CSV,  # Specify CSV as source\n",
        "    autodetect=True,  # Auto-detect schema based on CSV\n",
        ")\n",
        "\n",
        "# Load data to BigQuery\n",
        "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "\n",
        "# Wait for the job to complete\n",
        "job.result()\n",
        "\n",
        "# Verify upload\n",
        "table = client.get_table(table_ref)  # Get the table information\n",
        "print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_ref}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm-O_N7RCJRN",
        "outputId": "602f002f-9665-4b24-839b-a8d4d6ada727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 653 rows and 19 columns to gcp-services-442706.data_management.jobs-transformed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8taCeUidCJuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}